<!DOCTYPE html>

<html>

<link rel="stylesheet" href="styles.css">

<head>
  <title>About Us</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,400;0,700;1,400;1,700&family=Source+Serif+Pro:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">  
</head>

<div id="nav">
  <a href="/">Return to home page.</a>
</div>

<div id="contact">
  Contact: Please email me at <a href="mailto:naoyaokamoto@live.com">naoyaokamoto@live.com</a>.
</div>

<div id="header">
  <h1>We want to create a place where everyone can feel free to open up.</h1>
</div>
  
<div id="content">
  <p>
    Existing crisis mental lifelines don’t do a sufficiently good job of protecting privacy. There are services that encrypt conversations, but there are companies who, entrusted by users with their information, have sold conversation data to companies to train ML models.
  </p>

  <p>
    When people talk about their mental health, they often come from a place of vulnerability and sensitivity. So it is natural for them to expect that their conversations be allotted some amount of privacy and security.
  </p>

  <p>
    I know that mental health tools can help people live better lives. I've personally used meditation apps, and I feel that they've helped me maintain a sense of calm. On the other hand, the data that users provide when they use mental health services might not be conferred the privacy that users expect. When people visit a medical office in the US, they can expect that their data will be handled in accordance with the Health Insurance Portability and Accountability Act (HIPAA), which provides protections for data that’s collected by healthcare professionals. Many people have turned to mental health apps, and it may seem like these would operate under similar rules, but some apps operate in a gray area where these rules don’t apply. Even if people read dense privacy policies, the policies may not make it clear how user information could be shared and utilized. Because information about mental health is so sensitive, I believe that users deserve to have a clear understanding of what sharing is going on.
  </p>

  <p>
    The violation of a user’s privacy, despite the user’s expectations, can have a profound impact on someone’s life. Shifting my focus away from mental health apps towards crisis mental health lifelines, people who call the latter are often in very stressful situations. They may be grappling with thoughts of depression or anxiety, and they may urgently need assistance. It is natural for someone in this situation to reach out to a mental health lifeline, but they may not be aware of how the information regarding their situation could be handled. They might not know, for example, that responders may send police if necessary, and that this might result in involuntary hospitalization or institutionalization. Involuntary commitment may make young people less likely to discuss suicidal thoughts in the future, and callers could end up with a large bill for treatment that they didn’t want.
  </p>

  <p>
    I know that mental health services, whatever form it takes, can help people live more authentic and fulfilled lives, helping them achieve their best selves. So much of our society is influenced by how people think, the relationships between people and the information that they share. Given that we live in a society driven by information, I believe that privacy should be a given, especially for topics as sensitive as mental health.
  </p>

  <p>
    Based on these beliefs, we strive to be a service that treats user privacy as a major premise; we believe that we are not fulfilling our mission if user confidentiality is not one of our top priorities.
  </p>

  <p>
    While we promise not to misuse your data, our commitments cannot be complete without security measures that back up our commitments. For this reason, we will be implementing end-to-end encryption to ensure that the hosts of this service and other software vendors that we use can’t access conversations. The only people who can see the conversations are the caller (user) and the responder (operator). 
  </p>

  <p>
    We understand that we might need to collect some data for operational purposes, like making sure that we are providing top-quality service. We will look into ways that we can collect this information, but we are committed to providing users with a clear, informed choice. If users are OK with this collection, they can opt-in to it. Otherwise, they don’t have to opt-in, and we won’t collect their data, or we’ll delete it as soon as possible after the call. (This may seem like an obvious thing, but none of the services we’ve looked into offer such transparency.)
  </p>

  <p>
    This will be a space where everyone can feel free to open up, without fear of retaliation or unintended negative consequences.
  </p>
</div>

</html>